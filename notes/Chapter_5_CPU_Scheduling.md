# Chapter 5

Subject: CPU Scheduling



# 5.1. Basic Concepts

Objective: to maximize CPU utilization 

- ëŒ€ê¸° ìƒíƒœì¼ ë•Œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
- ready queueì— ë„£ì–´ë’€ë‹¤ê°€ ì‹¤í–‰

### CPU-I/O Burst Cycle

CPU burst â†’ I/O burst ë°˜ë³µ

### CPU Scheduler

ready queue(FIFO)ì— ìˆëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì„ íƒí•˜ê³  CPUì— í• ë‹¹

CPU Schedulingì´ ì´ë£¨ì–´ì§€ëŠ” ìƒí™©

1. runningâ†’waiting
2. running â†’ ready ex) interrupt
3. waiting â†’ ready ex) completion of I/O
4. terminate

**Nonpreemptive**: í”„ë¡œì„¸ìŠ¤ê°€ ê³„ì† CPUë¥¼ ì ìœ  ex) 1&4

**Preemptive**: state ë³€ê²½ ê°€ëŠ¥ ex) 2&3

- race condition ë°œìƒ ê°€ëŠ¥

### Dispatcher

![https://i.imgur.com/H23SQcU.png](https://i.imgur.com/H23SQcU.png)

í”„ë¡œì„¸ìŠ¤ê°€ CPUì˜ coreì— ëŒ€í•œ ì œì–´í•  ìˆ˜ ìˆê²Œ

- switching context
- switching to user mode
- PCë¥¼ user programìœ¼ë¡œ ì´ë™

# 5.2. Scheduling Criteria

ìŠ¤ì¼€ì¥´ë§ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•˜ëŠ” ê¸°ì¤€

- CPU ì‚¬ìš©: 40-80%
- Throughput: ì™„ë£Œí•œ í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜
- Turnaround time: í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¶€í„° ì™„ë£Œê¹Œì§€ì˜ ì‹œê°„(wait + execute + I/O)
- **Waiting time**: ready queueì—ì„œ ëŒ€ê¸°í•˜ëŠ” ì‹œê°„
- Response time: output ì¶œë ¥ì„ ì‹œì‘í•œ ì‹œê°„

Optimization: avg measures / íŠ¹ì • criteriaì— ì´ˆì 

# 5.3. Scheduling Algorithms

- 1 CPU Burst per process
- avg waiting time ë¹„êµ
- 1 core

## FCFS

![https://i.imgur.com/VAuh9Gf.png](https://i.imgur.com/VAuh9Gf.png)

First-Come, First-Served w/ FIFO queue

Nonpreemptive

### Convoy Effect

í° í”„ë¡œì„¸ìŠ¤ê°€ ëë‚  ë•Œê¹Œì§€ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ë“¤ì´ ê¸°ë‹¤ë ¤ì•¼ í•¨

## SJF

![https://i.imgur.com/DSZeLLh.png](https://i.imgur.com/DSZeLLh.png)

Shortest-Job-First

avg waiting timeì´ ì¤„ì–´ë“¤ë„ë¡

Preemptive â†’ SJF, Nonpreemptive â†’ SRTF(Shortest-Remaining-Time-First, ë‚¨ì•„ ìˆëŠ” ì‹œê°„ì´ ì§§ì€ ê±¸ ë¨¼ì € ì‹¤í–‰)

### Implementation promblem

ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ì˜ remaining CPU burstì˜ ê¸¸ì´ë¥¼ ì•Œ ìˆ˜ê°€ ì—†ìŒ

â†’ ì´ì „ í”„ë¡œì„¸ìŠ¤ë“¤ì˜ CPU burstì˜ exp. avg. ë¥¼ ì´ìš©í•´ì„œ ë‹¤ìŒ CPU burstì„ ì˜ˆì¸¡

## Round-Robin Scheduling

![https://i.imgur.com/zyeOHSq.png](https://i.imgur.com/zyeOHSq.png)

Preemptive

Time quantum: í•œ ë²ˆ ì‹¤í–‰í•˜ëŠ” ì‹œê°„

## Priority Scheduling

![https://i.imgur.com/0QzxO67.png](https://i.imgur.com/0QzxO67.png)

ìš°ì„ ìˆœìœ„ë¥¼ ì§€ì •í•˜ì—¬ ì‹¤í–‰

Preemptive: ë“¤ì–´ì˜¤ëŠ” í”„ë¡œì„¸ìŠ¤ê°€ prioiryê°€ ë†’ë‹¤ë©´ ëŒ€ì²´
Nonpreemptive: ì‹¤í–‰í•˜ë˜ í”„ë¡œì„¸ìŠ¤ë¶€í„°

### Starvation

ë‚®ì€ ìš°ì„ ìˆœìœ„ì˜ í”„ë¡œì„¸ìŠ¤ê°€ ëŠ¦ê²Œ ì‹¤í–‰ë˜ëŠ” ë¬¸ì œ

â†’ RRê³¼ ê²°í•©í•˜ì—¬ ê°™ì€ ìš°ì„ ìˆœìœ„ì˜ í”„ë¡œì„¸ìŠ¤ë“¤ì„ ëŒì•„ê°€ë©´ì„œ ì‹¤í–‰

## Multilevel Queue Scheduling

![https://i.imgur.com/kCmdRwl.png](https://i.imgur.com/kCmdRwl.png)

ì„ì˜ì˜ ê¸°ì¤€ì— ë”°ë¼ Queueë¥¼ ìƒì„±í•˜ê³  Queue ë‚´ë¶€ì—ì„œ ë”°ë¡œ ìŠ¤ì¼€ì¥´ë§ì„ ìˆ˜í–‰

## Multilevel Feedback Queue Scheduling

![Untitled](Chapter%205%2000bd4bc34ae340ecb4f9012501327e7c/Untitled.png)

feedbackì— ë”°ë¼ queue ì‚¬ì´ì˜ í”„ë¡œì„¸ìŠ¤ê°€ ì´ë™í•  ìˆ˜ ìˆìŒ

params ìˆ˜ê°€ ë„ˆë¬´ ë§ì´ í•„ìš”í•¨

# 5.4. Thread Scheduling

Process-contention scope(PCS): thread ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìŠ¤ì¼€ì¥´ë§

System-contention scope(SCS): OSê°€ ìŠ¤ì¼€ì¥´ë§

# 5.5 Multi-Processor Scheduling

## Multiprocessor

- multicore CPUs / multithreaded cores / NUMA / Heterogeneous multiprocessing

### Approaches

- Asymmetric: Master serverê°€ ì „ë‹´, bottleneck ë°œìƒ
- Symmetric(SMP): ê° í”„ë¡œì„¸ì„œê°€ self-scheduling

## Multicore Processors

![https://i.imgur.com/KFXYVkL.png](https://i.imgur.com/KFXYVkL.png)

SMP systems ex) CMT(Chip Multithreading)

memory stall: CPUê°€ ë©”ëª¨ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ì½ê±°ë‚˜ ì“¸ ë•Œ ë°œìƒí•˜ëŠ” ì§€ì—° ì‹œê°„ìœ¼ë¡œ ì¸í•´ í”„ë¡œì„¸ì„œê°€ ëŒ€ê¸°í•˜ëŠ” ìƒíƒœ

â†’ cache miss(much faster than memory)

## Multithreading a processing core

concurrent(not parallel), sharing-aware(ë™ì‹œ ì‹¤í–‰ í•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ í”„ë¡œì„¸ì„œì— í• ë‹¹)

![https://i.imgur.com/P1RMOXR.png](https://i.imgur.com/P1RMOXR.png)

1. Course grained
    - long-latency eventê°€ ë°œìƒí•  ë•Œê¹Œì§€ ì‹¤í–‰(ì£¼ê¸°ê°€ ê¸¸ë‹¤)
    - pipeline flushing: thread switching(HW, â†”context switching)ì— high cost
2. Fine-grained
    - thread switching @ boundary of instruction cycle (ì£¼ê¸°ê°€ ì§§ë‹¤)
    - no pipeline flushing: small cost

### Load Balancing

ëª¨ë“  í”„ë¡œì„¸ì„œì— workloadë¥¼ ê· ë“±í•˜ê²Œ ë°°ë¶„

1. Push Migration: ì£¼ê¸°ì ìœ¼ë¡œ loadë¥¼ ì²´í¬í•˜ì—¬ threadë¥¼ ì´ë™
2. Pull Migration: Idle í”„ë¡œì„¸ì„œê°€ taskë¥¼ ê°€ì ¸ì™€ì„œ ì‹¤í–‰

### Processor Affinity

ê°™ì€ í”„ë¡œì„¸ì„œì—ì„œ ê³„ì†í•´ì„œ threadë¥¼ ì‹¤í–‰ â†’ warm cache

- soft affinity: ë°˜ë“œì‹œ ê°™ì€ í”„ë¡œì„¸ì„œì—ì„œ ë™ì‘í•˜ì§€ëŠ” ì•ŠìŒ
- hard affinity: ì–´ë–¤ í”„ë¡œì„¸ì„œì—ì„œ ì‹¤í–‰í• ì§€ system callì„ í™œìš©í•˜ì—¬ ì§€ì •

<aside>
ğŸ’¡ Load Balancing & Processor Affinity ì‚¬ì´ì˜ tradeoffë¥¼ ì°¾ì•„ì•¼ í•¨

</aside>

### NUMA: non-uniform memory access

![https://i.imgur.com/vnPAcqm.png](https://i.imgur.com/vnPAcqm.png)

### Heterogenous Multiprocessing(HMP)

ì—¬ëŸ¬ ì¢…ë¥˜ì˜ í”„ë¡œì„¸ì„œë¥¼ í•¨ê»˜ ì‚¬ìš©